---
title: A/B Testing
author: tristan
date: '2018-10-03'
slug: a-b-testing
categories: [analytics]
tags: []
draft: true
type: commentary
featured: ["https://research.fb.com/efficient-tuning-of-online-systems-using-bayesian-optimization/","http://hookedondata.org/Guidelines-for-AB-Testing/"]
---

> A/B tests are often used as one-shot experiments for improving a product. In our paper (…), we describe how we use an AI technique called Bayesian optimization to adaptively design rounds of A/B tests based on the results of prior tests. Compared to a grid search or manual tuning, Bayesian optimization allows us to jointly tune more parameters with fewer experiments and find better values.

The post goes into examples and shares data from usage Facebook’s just-published methodology. Important.
[https://research.fb.com/efficient-tuning-of-online-systems-using-bayesian-optimization/](research.fb.com)


## 12 Guidelines for A/B Testing from Etsy
Emily Robinson’s A/B testing post is the single best I’ve read on the topic. This is not entirely surprising: Emily honed her A/B testing skills at Etsy, one of the pioneers of modern online experimentation. In the post, you get a glimpse of Etsy’s experimentation machine, and 12 clear rules for how to run experiments. If you’ve run many A/B tests before, you’ve almost definitely violated most of them at some point (I certainly have).
[http://hookedondata.org/Guidelines-for-AB-Testing/](hookedondata.org)